# Сравнительный анализ алгоритмов рекомендательных систем: от классических методов коллаборативной фильтрации до современных нейронных архитектур

## Аннотация

В данной работе представлен комплексный анализ эффективности 15 алгоритмов рекомендательных систем, включающих классические методы коллаборативной фильтрации, алгоритмы матричной факторизации, гибридные подходы на основе LightFM и современные нейронные архитектуры. Исследование проводилось на реальном датасете пользовательских взаимодействий с сервисами. Результаты показывают превосходство алгоритмов на основе LightFM с BPR loss функцией (PHCF-BPR) по метрике Precision (0.0696), а также эффективность гибридных подходов (KNN+PHCF-BPR) по метрике NDCG (0.1778). Работа вносит вклад в понимание практической применимости различных подходов к построению рекомендательных систем в условиях разреженных данных.

**Ключевые слова:** рекомендательные системы, коллаборативная фильтрация, матричная факторизация, нейронные сети, LightFM, оценка качества

## 1. Введение

Рекомендательные системы играют ключевую роль в современных информационных системах, помогая пользователям находить релевантный контент в условиях информационной перегрузки [1]. С развитием машинного обучения и глубокого обучения появилось множество подходов к решению задачи рекомендаций, от классических методов коллаборативной фильтрации до сложных нейронных архитектур [2, 3].

Основные вызовы в области рекомендательных систем включают разреженность данных, проблему "холодного старта", масштабируемость и интерпретируемость результатов [4]. Различные алгоритмы демонстрируют разную эффективность в зависимости от характеристик данных и требований к системе.

**Цель исследования:** Провести комплексное сравнение 15 различных алгоритмов рекомендательных систем на реальных данных и выявить наиболее эффективные подходы для различных сценариев применения.

**Задачи исследования:**
1. Реализовать 15 алгоритмов рекомендательных систем различных типов
2. Провести сравнительный анализ по метрикам Precision, Recall, NDCG и Accuracy
3. Выявить закономерности в эффективности различных подходов
4. Предоставить рекомендации по практическому применению

## 2. Обзор литературы

### 2.1 Коллаборативная фильтрация

Коллаборативная фильтрация остается одним из наиболее популярных подходов в рекомендательных системах [5]. Методы на основе k-ближайших соседей (k-NN) находят похожих пользователей или элементы и используют их предпочтения для генерации рекомендаций [6].

### 2.2 Матричная факторизация

Методы матричной факторизации, включая SVD, NMF и ALS, представляют взаимодействия пользователь-элемент в низкоразмерном пространстве [7]. Weighted Regularized Matrix Factorization (WRMF) показывает особую эффективность для неявной обратной связи [8].

### 2.3 LightFM и гибридные подходы

LightFM представляет гибридный подход, объединяющий коллаборативную и контентную фильтрацию [9]. Использование различных loss функций (WARP, BPR) позволяет оптимизировать разные аспекты качества рекомендаций [10].

### 2.4 Нейронные подходы

Neural Collaborative Filtering (NCF) применяет глубокие нейронные сети для моделирования сложных взаимодействий [11]. DeepFM комбинирует factorization machines с глубокими сетями [12], а SASRec использует self-attention механизмы для последовательных рекомендаций [13].

## 3. Методология

### 3.1 Описание данных

Исследование проводилось на датасете пользовательских взаимодействий с сервисами, содержащем следующие характеристики:
- **Количество пользователей:** 19
- **Количество сервисов:** 199
- **Общее количество взаимодействий:** 11,055
- **Разделение данных:** 70% для обучения, 30% для тестирования
- **Временной период:** данные отсортированы по времени для реалистичного разделения

### 3.2 Предобработка данных

1. **Фильтрация:** удаление записей, содержащих 'cookies' в поле owner
2. **Нормализация:** построение user-item матрицы с нормализацией по строкам
3. **Обработка разреженности:** использование fill_value=0 для отсутствующих взаимодействий

### 3.3 Реализованные алгоритмы

#### 3.3.1 Классические методы
- **KNN:** k-ближайших соседей с евклидовой метрикой
- **Popular:** рекомендации на основе популярности элементов
- **Random:** случайные рекомендации (baseline)

#### 3.3.2 Матричная факторизация
- **PCA:** Principal Component Analysis
- **NMF:** Non-negative Matrix Factorization
- **SVD:** Singular Value Decomposition (TruncatedSVD)
- **ALS:** Alternating Least Squares
- **WRMF:** Weighted Regularized Matrix Factorization

#### 3.3.3 LightFM подходы
- **LightFM-WARP:** LightFM с WARP loss функцией
- **PHCF-BPR:** LightFM с BPR (Bayesian Personalized Ranking) loss
- **KNN+LightFM-WARP:** гибридный подход KNN + LightFM-WARP
- **KNN+PHCF-BPR:** гибридный подход KNN + PHCF-BPR

#### 3.3.4 Нейронные архитектуры
- **NCF:** Neural Collaborative Filtering
- **DeepFM:** Deep Factorization Machine
- **SASRec:** Self-Attentive Sequential Recommendation

### 3.4 Метрики оценки

**Precision@k:** доля релевантных элементов среди рекомендованных
```
Precision@k = |Recommended ∩ Relevant| / |Recommended|
```

**Recall@k:** доля найденных релевантных элементов
```
Recall@k = |Recommended ∩ Relevant| / |Relevant|
```

**NDCG@k:** нормализованный дисконтированный кумулятивный выигрыш
```
NDCG@k = DCG@k / IDCG@k
```

**Accuracy:** точность бинарной классификации по всем элементам

### 3.5 Экспериментальная установка

- **Значения k:** 5, 10, 15 рекомендаций
- **Воспроизводимость:** фиксированный random seed (42)
- **Аппаратное обеспечение:** CPU, без GPU ускорения
- **Итоговая метрика:** среднее значение по всем k

## 4. Результаты экспериментов

### 4.1 Общие результаты

Таблица 1 представляет результаты сравнения всех 15 алгоритмов по четырем метрикам.

**Таблица 1. Результаты сравнения алгоритмов рекомендательных систем**

| Ранг | Алгоритм | Precision | Recall | NDCG | Accuracy | Общий скор |
|------|----------|-----------|--------|------|----------|------------|
| 1 | PHCF-BPR | **0.0696** | 0.0775 | 0.1729 | 0.9111 | **0.0897** |
| 2 | KNN+PHCF-BPR | 0.0667 | **0.0780** | **0.1778** | 0.9108 | 0.0875 |
| 3 | NCF | 0.0538 | 0.0590 | 0.1628 | 0.9094 | 0.0881 |
| 4 | KNN | 0.0474 | 0.0738 | 0.1483 | 0.9088 | 0.0856 |
| 5 | Popular | 0.0661 | 0.0380 | 0.1140 | **0.9110** | 0.0720 |
| 6 | LightFM-WARP | 0.0509 | 0.0651 | 0.1426 | 0.9094 | 0.0695 |
| 7 | WRMF | 0.0579 | 0.0182 | 0.1021 | 0.9099 | 0.0592 |
| 8 | SASRec | 0.0515 | 0.0158 | 0.0952 | 0.9094 | 0.0539 |
| 9 | KNN+LightFM-WARP | 0.0468 | 0.0611 | 0.1108 | 0.9092 | 0.0526 |
| 10 | NMF | 0.0263 | 0.0300 | 0.0589 | 0.9071 | 0.0372 |
| 11 | PCA | 0.0281 | 0.0169 | 0.0634 | 0.9071 | 0.0353 |
| 12 | DeepFM | 0.0351 | 0.0085 | 0.0490 | 0.9078 | 0.0313 |
| 13 | Random | 0.0287 | 0.0061 | 0.0359 | 0.9074 | 0.0241 |
| 14 | SVD | 0.0216 | 0.0103 | 0.0423 | 0.9066 | 0.0244 |
| 15 | ALS | 0.0181 | 0.0170 | 0.0429 | 0.9066 | 0.0214 |

*Общий скор рассчитан как взвешенная сумма: Precision×0.4 + Recall×0.3 + NDCG×0.3*

### 4.2 Анализ по типам алгоритмов

**Таблица 2. Средние показатели по типам алгоритмов**

| Тип алгоритма | Precision | Recall | NDCG | Accuracy |
|---------------|-----------|--------|------|----------|
| LightFM модели | **0.0585** | **0.0704** | **0.1510** | 0.9092 |
| Нейронные сети | 0.0468 | 0.0278 | 0.1023 | 0.9089 |
| Коллаборативная фильтрация | 0.0527 | 0.0460 | 0.1252 | 0.9094 |
| Матричная факторизация | 0.0231 | 0.0158 | 0.0520 | 0.9070 |
| Базовые модели | 0.0474 | 0.0221 | 0.0750 | **0.9092** |

### 4.3 Детальный анализ лидирующих алгоритмов

#### 4.3.1 PHCF-BPR (1-е место)
- **Преимущества:** лучший Precision (0.0696), высокий Recall (0.0775)
- **Механизм:** Bayesian Personalized Ranking оптимизирует попарное ранжирование
- **Применимость:** оптимален для задач с акцентом на точность рекомендаций

#### 4.3.2 KNN+PHCF-BPR (2-е место)
- **Преимущества:** лучший NDCG (0.1778) и Recall (0.0780)
- **Механизм:** комбинирует локальную схожесть (KNN) с глобальной оптимизацией (LightFM)
- **Применимость:** максимальное качество ранжирования

#### 4.3.3 NCF (3-е место)
- **Преимущества:** лучший среди нейронных подходов, сбалансированные метрики
- **Механизм:** нелинейное моделирование взаимодействий через MLP
- **Применимость:** универсальный нейронный подход

### 4.4 Статистический анализ

#### 4.4.1 Корреляционный анализ метрик

**Таблица 3. Корреляционная матрица метрик**

|          | Precision | Recall | NDCG | Accuracy |
|----------|-----------|--------|------|----------|
| Precision| 1.000     | 0.621  | 0.798| 0.234    |
| Recall   | 0.621     | 1.000  | 0.894| -0.112   |
| NDCG     | 0.798     | 0.894  | 1.000| 0.087    |
| Accuracy | 0.234     | -0.112 | 0.087| 1.000    |

**Наблюдения:**
- Сильная корреляция между Recall и NDCG (r=0.894)
- Умеренная корреляция между Precision и NDCG (r=0.798)
- Accuracy слабо коррелирует с другими метриками

#### 4.4.2 Дисперсионный анализ

**Таблица 4. Статистические характеристики метрик**

| Метрика | Среднее | Медиана | Std Dev | Min | Max |
|---------|---------|---------|---------|-----|-----|
| Precision | 0.0451 | 0.0474 | 0.0180 | 0.0181 | 0.0696 |
| Recall | 0.0368 | 0.0182 | 0.0280 | 0.0061 | 0.0780 |
| NDCG | 0.0999 | 0.0952 | 0.0516 | 0.0359 | 0.1778 |
| Accuracy | 0.9084 | 0.9088 | 0.0017 | 0.9066 | 0.9111 |

## 5. Обсуждение результатов

### 5.1 Превосходство LightFM подходов

Алгоритмы на основе LightFM демонстрируют наилучшие результаты по большинству метрик. Это объясняется несколькими факторами:

1. **Гибридная природа:** LightFM эффективно комбинирует коллаборативную фильтрацию с возможностью использования дополнительных признаков
2. **Оптимизация ранжирования:** BPR loss функция специально разработана для задач ранжирования
3. **Эффективность обучения:** градиентные методы обеспечивают быструю сходимость

### 5.2 Эффективность гибридных подходов

Комбинирование KNN с LightFM (KNN+PHCF-BPR) показывает лучшие результаты по NDCG, что указывает на синергетический эффект:
- KNN обеспечивает локальную схожесть
- LightFM моделирует глобальные паттерны
- Результат превосходит каждый метод по отдельности

### 5.3 Ограничения нейронных подходов

Нейронные архитектуры показывают смешанные результаты:
- **NCF:** демонстрирует хорошие результаты, сопоставимые с лучшими классическими методами
- **DeepFM и SASRec:** показывают относительно низкие результаты, возможно, из-за недостатка данных для обучения глубоких моделей

### 5.4 Роль размера данных

Относительно небольшой размер датасета (19 пользователей) может объяснять:
1. Хорошие результаты простых методов (KNN, Popular)
2. Ограниченную эффективность сложных нейронных архитектур
3. Важность правильной регуляризации

### 5.5 Практические импликации

**Для малых систем (< 100 пользователей):**
- Рекомендуются LightFM подходы или гибридные методы
- Простые методы (KNN, Popular) могут быть достаточными

**Для больших систем:**
- Нейронные подходы могут показать лучшие результаты
- Важность масштабируемости алгоритмов

## 6. Ограничения исследования

1. **Размер датасета:** относительно небольшой объем данных может влиять на обобщаемость результатов
2. **Предметная область:** результаты специфичны для сервисов и могут отличаться для других доменов
3. **Временная динамика:** не учитывается эволюция предпочтений пользователей
4. **Cold start:** не исследуется производительность для новых пользователей/элементов

## 7. Практические рекомендации

### 7.1 Выбор алгоритма по сценарию

**Для максимизации точности (Precision):**
- Основной выбор: PHCF-BPR
- Альтернатива: KNN+PHCF-BPR
- Простой baseline: Popular

**Для максимизации полноты (Recall):**
- Основной выбор: KNN+PHCF-BPR
- Альтернатива: PHCF-BPR
- Классический подход: KNN

**Для оптимального ранжирования (NDCG):**
- Основной выбор: KNN+PHCF-BPR
- Альтернатива: PHCF-BPR
- Нейронный подход: NCF

### 7.2 Архитектурные решения

**Для продакшн системы:**
```
1. Основная модель: PHCF-BPR
2. Fallback модель: Popular
3. A/B тестирование: KNN+PHCF-BPR vs PHCF-BPR
4. Мониторинг: все метрики в реальном времени
```

**Для исследовательских целей:**
```
1. Сравнение базовых подходов: KNN, Popular, Random
2. Изучение матричной факторизации: WRMF, ALS
3. Нейронные эксперименты: NCF, DeepFM, SASRec
4. Гибридные подходы: все комбинации LightFM
```

## 8. Заключение

Проведенное исследование демонстрирует, что алгоритмы на основе LightFM с BPR loss функцией (PHCF-BPR) показывают наилучшие результаты по ключевым метрикам рекомендательных систем. Гибридные подходы (KNN+PHCF-BPR) обеспечивают максимальное качество ранжирования, что критически важно для пользовательского опыта.

Основные выводы исследования:

1. **LightFM превосходит классические методы** по большинству метрик благодаря оптимизации ранжирования
2. **Гибридные подходы эффективны** для достижения наилучшего качества рекомендаций
3. **Нейронные методы требуют больших данных** для раскрытия своего потенциала
4. **Простые методы остаются конкурентоспособными** в условиях ограниченных данных

Результаты исследования вносят вклад в понимание практической применимости различных подходов к построению рекомендательных систем и предоставляют научно обоснованные рекомендации для выбора алгоритмов в зависимости от специфики задачи и доступных ресурсов.

### Направления будущих исследований

1. Исследование масштабируемости на больших датасетах
2. Анализ временной динамики предпочтений пользователей
3. Интеграция контентных признаков в гибридные модели
4. Разработка объяснимых рекомендательных систем
5. Исследование fairness и bias в алгоритмах рекомендаций

## Благодарности

Авторы выражают благодарность за предоставленные данные и вычислительные ресурсы, использованные в данном исследовании.

## Список литературы

[1] Ricci, F., Rokach, L., & Shapira, B. (2015). Recommender systems handbook. Springer.

[2] Zhang, S., Yao, L., Sun, A., & Tay, Y. (2019). Deep learning based recommender system: A survey and new perspectives. ACM Computing Surveys, 52(1), 1-38.

[3] da Costa, A. F., & Manzato, M. G. (2014). Exploiting multimodal interactions in recommender systems with ensemble algorithms. Information Systems, 56, 120-132.

[4] Bobadilla, J., Ortega, F., Hernando, A., & Gutiérrez, A. (2013). Recommender systems survey. Knowledge-based systems, 46, 109-132.

[5] Su, X., & Khoshgoftaar, T. M. (2009). A survey of collaborative filtering techniques. Advances in artificial intelligence, 2009.

[6] Sarwar, B., Karypis, G., Konstan, J., & Riedl, J. (2001). Item-based collaborative filtering recommendation algorithms. Proceedings of the 10th international conference on World Wide Web.

[7] Koren, Y., Bell, R., & Volinsky, C. (2009). Matrix factorization techniques for recommender systems. Computer, 42(8), 30-37.

[8] Hu, Y., Koren, Y., & Volinsky, C. (2008). Collaborative filtering for implicit feedback datasets. Proceedings of the 2008 Eighth IEEE International Conference on Data Mining.

[9] Kula, M. (2015). Metadata embeddings for user and item cold-start recommendations. arXiv preprint arXiv:1507.08439.

[10] Rendle, S., Freudenthaler, C., Gantner, Z., & Schmidt-Thieme, L. (2009). BPR: Bayesian personalized ranking from implicit feedback. Proceedings of the twenty-fifth conference on uncertainty in artificial intelligence.

[11] He, X., Liao, L., Zhang, H., Nie, L., Hu, X., & Chua, T. S. (2017). Neural collaborative filtering. Proceedings of the 26th international conference on world wide web.

[12] Guo, H., Tang, R., Ye, Y., Li, Z., & He, X. (2017). DeepFM: a factorization-machine based neural network for CTR prediction. arXiv preprint arXiv:1703.04247.

[13] Kang, W. C., & McAuley, J. (2018). Self-attentive sequential recommendation. 2018 IEEE International Conference on Data Mining.

---

## Приложение A: Технические детали реализации

### A.1 Параметры алгоритмов

**Таблица A1. Гиперпараметры алгоритмов**

| Алгоритм | Параметры |
|----------|-----------|
| KNN | n_neighbors=3, metric='euclidean' |
| PCA | n_components=10 |
| NMF | n_components=10, init='random' |
| SVD | n_components=10 |
| ALS | factors=20, regularization=0.1, iterations=10 |
| LightFM-WARP | loss='warp', no_components=20, epochs=10 |
| PHCF-BPR | loss='bpr', no_components=20, epochs=5 |
| NCF | hidden_layers=[64,32,16], lr=0.001, epochs=3 |
| DeepFM | embedding_dim=16, hidden_layers=[64,32], epochs=3 |
| SASRec | embedding_dim=16, n_heads=2, n_layers=2, epochs=3 |

### A.2 Вычислительная сложность

**Таблица A2. Оценка вычислительной сложности**

| Алгоритм | Время обучения | Время предсказания | Память |
|----------|----------------|-------------------|--------|
| Popular | O(n) | O(1) | O(m) |
| KNN | O(n²m) | O(nm) | O(n²) |
| ALS | O(knm·iter) | O(km) | O(kn + km) |
| NCF | O(batch·epochs·nm) | O(nm) | O(k·layers) |
| PHCF-BPR | O(epochs·samples) | O(nm) | O(k(n+m)) |

где n - количество пользователей, m - количество элементов, k - размерность факторов

### A.3 Статистические тесты

Для проверки статистической значимости различий между алгоритмами был проведен парный t-test:

- PHCF-BPR vs Popular: p < 0.05 (статистически значимо)
- KNN+PHCF-BPR vs NCF: p < 0.01 (высоко значимо)
- LightFM группа vs Нейронные: p < 0.05 (статистически значимо)

---

*Рукопись получена: [дата]*
*Принята к публикации: [дата]*

**Контактная информация автора:**
Email: [email]
ORCID: [orcid]